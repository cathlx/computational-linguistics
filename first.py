import nltk
from nltk.tokenize import word_tokenize
from nltk.tokenize import sent_tokenize


# nltk.download('punkt')

text = 'Весна в пред. году была поздней... зато дружной.В т*и дня снег, которого навалило очень уж много, превратился в ревущие потоки. Спустившись по многочисленным оврагам с гор, они устремились вниз, и река, умолкшая на всю зиму...'
tokens = word_tokenize(text)
print(tokens)

tok_sent = sent_tokenize(text)
print(tok_sent)

'''не разделяет предложения если после точки нет пробела
сокращения с точкой принимает за конец предложения
считает @ как отдельный токен
не считает токеном целое зацензуренное слово (часть букв заменена звездочками)'''
